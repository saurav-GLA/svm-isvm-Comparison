{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4adb5df",
   "metadata": {},
   "source": [
    "\n",
    "# Incremental SVM vs Traditional SVM  \n",
    "**Dataset:** Kaggle Fraud Detection Dataset  \n",
    "‚ö†Ô∏è *Note: Due to no internet access inside this notebook environment, you must manually upload the dataset (CSV file) into `/mnt/data/` before running the notebook.*\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Objective\n",
    "Traditional SVM needs full retraining whenever new data arrives ‚Äî too slow for streaming systems.  \n",
    "Incremental SVM (ISVM) updates the model continuously without forgetting old knowledge.\n",
    "\n",
    "This notebook compares:\n",
    "- Training time of Traditional SVM vs Incremental SVM  \n",
    "- Accuracy comparison  \n",
    "- Update time when new data streams in  \n",
    "- Visualizations using Matplotlib  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Load dataset (user must upload the CSV file to /mnt/data)\n",
    "df = pd.read_csv('/mnt/data/fraudDataset.csv')  # CHANGE FILENAME IF NEEDED\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994925a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic preprocessing\n",
    "df = df.sample(20000)  # use smaller subset for timing comparison\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Traditional SVM (Full retraining)\n",
    "svm = SVC(kernel='rbf')\n",
    "\n",
    "start = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_train_time = time.time() - start\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "svm_train_time, svm_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de7dc5f",
   "metadata": {},
   "source": [
    "## Incremental SVM (ISVM) using `SGDClassifier` with hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a0a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "isvm = SGDClassifier(loss='hinge')\n",
    "\n",
    "batch_size = 2000\n",
    "start = time.time()\n",
    "\n",
    "for i in range(0, len(X_train), batch_size):\n",
    "    X_batch = X_train[i:i+batch_size]\n",
    "    y_batch = y_train.iloc[i:i+batch_size]\n",
    "    isvm.partial_fit(X_batch, y_batch, classes=np.unique(y))\n",
    "\n",
    "isvm_train_time = time.time() - start\n",
    "\n",
    "y_pred_isvm = isvm.predict(X_test)\n",
    "isvm_acc = accuracy_score(y_test, y_pred_isvm)\n",
    "\n",
    "isvm_train_time, isvm_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ba067",
   "metadata": {},
   "source": [
    "## Streaming New Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba7e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate new streaming data arrival\n",
    "new_data = X_train[:1500]\n",
    "new_labels = y_train[:1500]\n",
    "\n",
    "start = time.time()\n",
    "isvm.partial_fit(new_data, new_labels)\n",
    "incremental_update_time = time.time() - start\n",
    "\n",
    "incremental_update_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff09486",
   "metadata": {},
   "source": [
    "## üìä Visualization Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare training times\n",
    "methods = ['Traditional SVM', 'Incremental SVM']\n",
    "times = [svm_train_time, isvm_train_time]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(methods, times)\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.show()\n",
    "\n",
    "# Accuracy comparison\n",
    "acc = [svm_acc, isvm_acc]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(methods, acc)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
